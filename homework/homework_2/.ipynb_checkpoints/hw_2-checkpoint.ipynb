{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import collections\n",
    "import math\n",
    "import operator\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/xiasong/Documents/Class_2016/DSE/DSE220/homework/homework_2\n",
      "Homework_2.pdf         mnist_test_data.csv    mnist_train_labels.csv\n",
      "hw_2.ipynb             mnist_test_labels.csv\n",
      "hw_2.pdf               mnist_train_data.csv\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data into python and check data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('mnist_train_data.csv')\n",
    "train_lab = pd.read_csv('mnist_train_labels.csv')\n",
    "test = pd.read_csv('mnist_test_data.csv')\n",
    "test_lab = pd.read_csv('mnist_test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5999, 784) (5999, 1) (999, 784) (999, 1)\n"
     ]
    }
   ],
   "source": [
    "print (train.shape, train_lab.shape, test.shape, test_lab.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1: Compute and report the prior probabilities πj for all labels. (10\n",
    "marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    4\n",
       "Name: 5, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lab['5'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(0, 592), (1, 671), (2, 581), (3, 608), (4, 623), (5, 513), (6, 608), (7, 651), (8, 551), (9, 601)]) {0: 592, 4: 623, 1: 671, 9: 601, 2: 581, 3: 608, 5: 513, 6: 608, 7: 651, 8: 551}\n",
      "-----------------------------------------------------------------------\n",
      "The prior probabilties of πj are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([(0, 0.0987),\n",
       "             (1, 0.1119),\n",
       "             (2, 0.0968),\n",
       "             (3, 0.1014),\n",
       "             (4, 0.1039),\n",
       "             (5, 0.0855),\n",
       "             (6, 0.1014),\n",
       "             (7, 0.1085),\n",
       "             (8, 0.0918),\n",
       "             (9, 0.1002)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count each class in train lab\n",
    "lab_count1=dict(collections.Counter(train_lab['5']))\n",
    "lab_count = collections.OrderedDict(sorted(lab_count1.items()))\n",
    "print (lab_count, lab_count1)\n",
    "print (\"-----------------------------------------------------------------------\")\n",
    "#calculate the fraction of each digit\n",
    "priors1=[]\n",
    "for k, v in lab_count.items():\n",
    "    a = (v/len(train_lab))\n",
    "    a = round(a,4)\n",
    "    priors1.append((k,a))\n",
    "priors2 = dict(priors1)\n",
    "priors = collections.OrderedDict(sorted(priors2.items()))\n",
    "print ('The prior probabilties of πj are:')\n",
    "priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "671"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_count1[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2: For each pixel Xi and label j, compute Pji = P(Xi = 1|y = j) (Use\n",
    "the maximum likelihood estimate shown in class). Use Laplacian Smoothing for\n",
    "computing Pji. Report the highest Pji for each label j. (15 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1119"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calcualte the pji\n",
    "df1 = pd.concat([train_lab, train], axis=1)\n",
    "Pji = []\n",
    "for j in range(10):\n",
    "    for i in range(1,785):\n",
    "        df2 = df1.ix[:,(0,i)] #from df1 extract the 0 and ith column\n",
    "        df3 = df2[(df2.iloc[:,0] == j) & (df2.iloc[:,1] > 0.9)]\n",
    "        pji = (len(df3)+1) / (lab_count1[j]+2)\n",
    "        Pji.append((j,pji))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hightest Pji for each label j are\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0.8519),\n",
       " (1, 0.9851),\n",
       " (2, 0.729),\n",
       " (3, 0.8082),\n",
       " (4, 0.8496),\n",
       " (5, 0.7126),\n",
       " (6, 0.8492),\n",
       " (7, 0.7948),\n",
       " (8, 0.8752),\n",
       " (9, 0.8673)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select the highest Pji for each label\n",
    "k = 783\n",
    "Pj = []\n",
    "for j in range(10):\n",
    "    n = [] \n",
    "    for i in range (784):\n",
    "        a = j * k + i\n",
    "        b = Pji[a][1]\n",
    "        b = round(b,4)\n",
    "        n.append(b)\n",
    "    c = max(n)\n",
    "    Pj.append((Pji[a][0],c))\n",
    "#Pj = dict(Pj)\n",
    "print (\"The hightest Pji for each label j are\")\n",
    "Pj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Question 3: Use naive bayes (as shown in lecture slides) to classify the test\n",
    "data. Report the accuracy. (5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# form the classifier\n",
    "k = 784\n",
    "argmax = []\n",
    "for i in range(len(test)):\n",
    "    a = test.iloc[i,:]\n",
    "    am = []\n",
    "    for j in range(10):\n",
    "        am1 = []\n",
    "        for m in range(784):\n",
    "            d = k * j + m\n",
    "            if a[m] > 0.9:\n",
    "                am2 = math.log(Pji[d][1])\n",
    "                am1.append(am2) \n",
    "        am3 = math.log(priors[j]) + sum(am1)\n",
    "        am.append(am3)\n",
    "    idx, val = max(enumerate(am), key=operator.itemgetter(1))\n",
    "    argmax.append((idx, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of model is 0.6706706706706707\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model results with accuracy\n",
    "labels_pre = []\n",
    "for i in range(len(argmax)):\n",
    "    a = argmax[i][0]\n",
    "    labels_pre.append(a)\n",
    "count = 0\n",
    "for i in range(len(labels_pre)):\n",
    "    if labels_pre[i] == test_lab.iloc[i,0]:\n",
    "        count = count + 1\n",
    "accuracy = count / len(test)\n",
    "\n",
    "print ('The accuracy of model is %s' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " Question 4: Compute the confusion matrix (as shown in the lectures) and report\n",
    "the top 3 pairs with most (absolute number) incorrect classi\f",
    "cations. (10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_tru = []\n",
    "for i in range(len(test_lab)):\n",
    "    a = test_lab.iloc[i,0]\n",
    "    labels_tru.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[81,  0,  0,  0,  0,  0,  0,  0,  4,  0],\n",
       "       [ 0, 60,  1,  2,  0,  0,  1,  0, 62,  0],\n",
       "       [ 5,  0, 92,  0,  0,  0,  1,  0, 18,  0],\n",
       "       [ 0,  0,  2, 91,  0,  1,  3,  0,  9,  1],\n",
       "       [ 2,  0,  2,  0, 59,  0,  3,  0, 28, 16],\n",
       "       [12,  0,  2, 18,  1, 10,  2,  1, 40,  1],\n",
       "       [ 8,  0,  4,  0,  1,  0, 68,  0,  6,  0],\n",
       "       [ 3,  0,  2,  3,  1,  0,  0, 58, 21, 10],\n",
       "       [ 3,  0,  2,  8,  0,  0,  0,  0, 76,  0],\n",
       "       [ 1,  0,  1,  2,  2,  0,  0,  0, 13, 75]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(labels_tru, labels_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion_matrix we can tell that the top 3 pairs of incorrect classification are (8,1), (8,5) and (8,4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5: Visualizing mistakes: Print two MNIST images from the test data\n",
    "that your classi\f",
    "er misclassi\f",
    "ed. Write both the true and predicted labels for\n",
    "both of these misclassi\f",
    "ed digits. (10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#find the index where the predicted labels do not match with true labels\n",
    "indicies = []\n",
    "for i in range(len(labels_tru)):\n",
    "    if labels_tru[i] != labels_pre[i]:\n",
    "        indicies.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEGCAYAAACq4kOvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f9ba400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEGCAYAAACq4kOvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmyXl8Jsl9f+lktIi8tHyswAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106fd6e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixels1 = np.array(test.iloc[339,:], dtype='uint8')\n",
    "pixels1 = np.array(pixels1, dtype='uint8')\n",
    "pixels2 = np.array(test.iloc[267,:], dtype='uint8')\n",
    "pixels2 = np.array(pixels2, dtype='uint8')\n",
    "# Reshape the array into 28 x 28 array (2-dimensional array)\n",
    "pixels1 = pixels1.reshape((28, 28))\n",
    "pixels2 = pixels2.reshape((28, 28))\n",
    "plt.title('Predict:%i, True:%i' %( labels_pre[339],labels_tru[339]), fontsize = 10)\n",
    "plt.imshow(pixels1, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Predict:%i, True:%i' %( labels_pre[267],labels_tru[267]), fontsize = 10)\n",
    "plt.imshow(pixels2, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will implement Gaussian Mixture Model and Linear Discriminant Anal-\n",
    "ysis on the breast cancer data (sklearn.datasets.load breast cancer) available in\n",
    "sklean.datasets. Load the data and split it into train-validation-test (40-20-40\n",
    "split). Don't shu\u000fe the data, otherwise your results will be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#download data\n",
    "from sklearn import datasets\n",
    "cancer = datasets.load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tra_val, X_tes, y_tra_val, y_tes = train_test_split(X, y, test_size=0.4, random_state=10)\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(X_tra_val, y_tra_val, test_size=0.33, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6: Implement Gaussian Mixture model on the data as shown in\n",
    "class. Tune the covariance type parameter on the validation data. Use the\n",
    "selected value to compute the test accuracy. As always, train the model on\n",
    "train+validation data to compute the test accuracy. (10 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.0833333333333 at covariance_tpye = full\n",
      "Test accuracy = 0.0614035087719 at covariance_tpye = tied\n",
      "Test accuracy = 0.618421052632 at covariance_tpye = diag\n",
      "Test accuracy = 0.0131578947368 at covariance_tpye = spherical\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize Gaussian Naive Bayes\n",
    "for cov_type in ('full', 'tied', 'diag', 'spherical'):\n",
    "    gm = GaussianMixture(n_components=3,covariance_type = cov_type)\n",
    "    # Train the classifier\n",
    "    gm.fit(X_val, y_val)\n",
    "    # Make predictions on test data\n",
    "    y_pre = gm.predict(X_tes)\n",
    "    accuracy = accuracy_score(y_pre, y_tes)\n",
    "    print ('Test accuracy = ' + str(accuracy) + ' at covariance_tpye = ' + cov_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.627192982456\n"
     ]
    }
   ],
   "source": [
    "#train the model on train+validation compute the test accuracy\n",
    "gm = GaussianMixture(n_components=3,covariance_type = 'diag')\n",
    "# Train the classifier\n",
    "gm.fit(X_tra_val, y_tra_val)\n",
    "# Make predictions on test data\n",
    "y_pre = gm.predict(X_tes)\n",
    "accuracy = accuracy_score(y_pre, y_tes)\n",
    "print ('Test accuracy = ' + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 7: Apply Linear Discriminant Analysis model on the train+validation\n",
    "data and report the accuracy obtained on test data. Report the transformation\n",
    "matrix (w) along with the intercept. (5 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.964912280702\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "# Train\n",
    "clf.fit(X_tra_val, y_tra_val)\n",
    "# Test\n",
    "y_pre = clf.predict(X_tes)\n",
    "\n",
    "# print the accuracy\n",
    "print ('Test accuracy = ' + str(np.sum(y_pred == y_tes)/len(y_tes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.26351958],\n",
       "       [ 1.50315616],\n",
       "       [-2.32016749],\n",
       "       [ 1.16950535],\n",
       "       [ 0.2848613 ],\n",
       "       [-1.64129414],\n",
       "       [-4.67284807],\n",
       "       [ 1.07672183],\n",
       "       [ 1.54651486],\n",
       "       [ 0.64701382],\n",
       "       [ 2.6571233 ],\n",
       "       [ 2.6550835 ],\n",
       "       [ 2.33859685],\n",
       "       [-1.94301274],\n",
       "       [-0.62044859],\n",
       "       [ 1.56540432],\n",
       "       [-2.78728741],\n",
       "       [-1.88634026],\n",
       "       [-3.01128946],\n",
       "       [-2.01215895],\n",
       "       [-2.28090759],\n",
       "       [ 0.19538998],\n",
       "       [ 0.98746004],\n",
       "       [ 2.46018487],\n",
       "       [ 0.75719225],\n",
       "       [ 1.98586354],\n",
       "       [-0.17125482],\n",
       "       [-1.79000126],\n",
       "       [ 0.6345923 ],\n",
       "       [ 1.13277611],\n",
       "       [ 1.95431583],\n",
       "       [ 1.55578335],\n",
       "       [ 2.27767368],\n",
       "       [-2.5074087 ],\n",
       "       [ 0.6818976 ],\n",
       "       [-3.09425256],\n",
       "       [ 0.84234254],\n",
       "       [ 1.8478171 ],\n",
       "       [-3.09161328],\n",
       "       [ 1.6580846 ],\n",
       "       [-4.66781657],\n",
       "       [-3.53785254],\n",
       "       [ 0.01061703],\n",
       "       [-3.52644023],\n",
       "       [-4.39173888],\n",
       "       [-3.97742522],\n",
       "       [ 0.7136343 ],\n",
       "       [-2.56682887],\n",
       "       [ 0.16736688],\n",
       "       [-0.53437683],\n",
       "       [ 0.45742099],\n",
       "       [-2.42677651],\n",
       "       [-3.24993441],\n",
       "       [ 2.1910091 ],\n",
       "       [ 2.26502519],\n",
       "       [ 3.00614952],\n",
       "       [ 0.36987022],\n",
       "       [ 1.76510543],\n",
       "       [ 1.53168051],\n",
       "       [-0.66814384],\n",
       "       [ 2.02608163],\n",
       "       [ 1.52369923],\n",
       "       [-1.0746215 ],\n",
       "       [ 2.38613088],\n",
       "       [ 0.48736284],\n",
       "       [ 2.67304958],\n",
       "       [ 1.98034775],\n",
       "       [ 2.82421242],\n",
       "       [ 2.88990787],\n",
       "       [ 1.39673677],\n",
       "       [-3.82025055],\n",
       "       [ 1.93758038],\n",
       "       [ 1.94176014],\n",
       "       [ 3.19922817],\n",
       "       [-1.54989079],\n",
       "       [ 2.32305695],\n",
       "       [ 1.18940218],\n",
       "       [ 0.33485357],\n",
       "       [ 1.09442284],\n",
       "       [-2.52958672],\n",
       "       [ 1.65248633],\n",
       "       [ 0.93877528],\n",
       "       [ 1.95175434],\n",
       "       [-0.11450118],\n",
       "       [-3.67915599],\n",
       "       [ 1.36368111],\n",
       "       [ 0.41469563],\n",
       "       [-1.57781689],\n",
       "       [-4.40443653],\n",
       "       [ 2.11796045],\n",
       "       [ 2.68429122],\n",
       "       [-2.24833047],\n",
       "       [ 0.61174463],\n",
       "       [-1.58364025],\n",
       "       [ 0.33827913],\n",
       "       [ 1.67093574],\n",
       "       [ 2.47372625],\n",
       "       [ 2.43059642],\n",
       "       [ 0.03639313],\n",
       "       [ 1.39252539],\n",
       "       [ 2.73374613],\n",
       "       [ 2.95749338],\n",
       "       [ 2.73987151],\n",
       "       [-3.29176706],\n",
       "       [-1.24034377],\n",
       "       [ 0.11160887],\n",
       "       [ 0.61975529],\n",
       "       [ 2.05028151],\n",
       "       [ 2.7159881 ],\n",
       "       [ 1.25969099],\n",
       "       [-0.04326319],\n",
       "       [ 3.36435354],\n",
       "       [ 2.80623592],\n",
       "       [ 1.59767118],\n",
       "       [ 1.63253362],\n",
       "       [-0.60943289],\n",
       "       [-1.12730396],\n",
       "       [-2.66453462],\n",
       "       [ 2.13837656],\n",
       "       [ 1.79770819],\n",
       "       [ 1.44712489],\n",
       "       [-3.54836594],\n",
       "       [ 0.44048716],\n",
       "       [-1.17713886],\n",
       "       [-4.10904651],\n",
       "       [ 1.32454223],\n",
       "       [ 1.60882719],\n",
       "       [ 2.18728652],\n",
       "       [-1.03093762],\n",
       "       [-0.6533685 ],\n",
       "       [ 1.63137155],\n",
       "       [-0.41645693],\n",
       "       [ 2.59924141],\n",
       "       [-2.24816589],\n",
       "       [-3.1459847 ],\n",
       "       [ 1.98937622],\n",
       "       [-1.36020434],\n",
       "       [-0.63768529],\n",
       "       [-3.41953189],\n",
       "       [ 3.63253057],\n",
       "       [-0.88803053],\n",
       "       [-3.9091635 ],\n",
       "       [ 0.66931436],\n",
       "       [-2.33941639],\n",
       "       [ 1.43077463],\n",
       "       [ 0.10006269],\n",
       "       [-1.34564361],\n",
       "       [ 1.44932118],\n",
       "       [-3.98385504],\n",
       "       [ 2.18630104],\n",
       "       [-2.80045787],\n",
       "       [-1.27161594],\n",
       "       [-1.77808606],\n",
       "       [ 2.56479755],\n",
       "       [ 2.20870558],\n",
       "       [-2.97128555],\n",
       "       [-3.73268854],\n",
       "       [-4.15598174],\n",
       "       [-4.41844542],\n",
       "       [-3.87747204],\n",
       "       [ 1.09729613],\n",
       "       [-0.49868037],\n",
       "       [ 2.97280551],\n",
       "       [ 1.95544007],\n",
       "       [ 0.23340982],\n",
       "       [-0.86176796],\n",
       "       [-3.96991237],\n",
       "       [ 1.71518009],\n",
       "       [-0.65741109],\n",
       "       [ 1.73661445],\n",
       "       [ 1.33604194],\n",
       "       [ 2.52680287],\n",
       "       [-2.15617805],\n",
       "       [ 2.6632635 ],\n",
       "       [ 2.31202283],\n",
       "       [-4.03617168],\n",
       "       [-3.79004332],\n",
       "       [-1.69663194],\n",
       "       [-0.19621714],\n",
       "       [-2.2772003 ],\n",
       "       [-2.41914942],\n",
       "       [ 1.86602708],\n",
       "       [-0.21655862],\n",
       "       [ 1.33881248],\n",
       "       [ 0.68443455],\n",
       "       [ 0.48606201],\n",
       "       [-3.68482244],\n",
       "       [ 0.80254731],\n",
       "       [-1.71378259],\n",
       "       [ 0.69499971],\n",
       "       [-1.29373305],\n",
       "       [-1.8618137 ],\n",
       "       [-3.57804698],\n",
       "       [ 1.38480087],\n",
       "       [ 1.48604639],\n",
       "       [ 0.70968973],\n",
       "       [ 1.28947416],\n",
       "       [ 1.23584191],\n",
       "       [-2.74564951],\n",
       "       [ 1.44234078],\n",
       "       [ 2.66270173],\n",
       "       [ 0.89335526],\n",
       "       [-3.32553755],\n",
       "       [ 0.91321742],\n",
       "       [-4.67408264],\n",
       "       [ 1.88104627],\n",
       "       [ 1.91715486],\n",
       "       [-3.21568003],\n",
       "       [ 1.46379354],\n",
       "       [ 1.59539346],\n",
       "       [ 2.01251945],\n",
       "       [-1.97524439],\n",
       "       [-2.74051937],\n",
       "       [ 2.06505852],\n",
       "       [ 0.85492584],\n",
       "       [-2.65585937],\n",
       "       [ 0.63088387],\n",
       "       [ 1.23316881],\n",
       "       [ 2.41424533],\n",
       "       [ 2.3152555 ],\n",
       "       [ 3.01391244],\n",
       "       [ 1.60041101],\n",
       "       [ 0.66088399],\n",
       "       [ 1.72874887],\n",
       "       [ 1.29028704],\n",
       "       [ 0.86551224],\n",
       "       [-0.61287151],\n",
       "       [-2.75522039],\n",
       "       [-3.26798461],\n",
       "       [ 1.01879334],\n",
       "       [ 0.42096869],\n",
       "       [-1.92334046],\n",
       "       [-2.97271615],\n",
       "       [-3.52612472],\n",
       "       [ 2.95575717],\n",
       "       [-1.32477957],\n",
       "       [ 2.00458434],\n",
       "       [ 1.51215824],\n",
       "       [ 1.538433  ],\n",
       "       [-1.79675245],\n",
       "       [ 1.56279549],\n",
       "       [-1.72434948],\n",
       "       [-2.38484597],\n",
       "       [ 2.30359771],\n",
       "       [ 0.2419641 ],\n",
       "       [-2.83219071],\n",
       "       [ 2.37593152],\n",
       "       [-3.18688253],\n",
       "       [-2.75986994],\n",
       "       [ 2.24654972],\n",
       "       [ 0.80827318],\n",
       "       [ 1.49845987],\n",
       "       [-1.6342343 ],\n",
       "       [ 1.52784871],\n",
       "       [ 1.00228895],\n",
       "       [-3.2151077 ],\n",
       "       [ 2.31793627],\n",
       "       [-3.01943999],\n",
       "       [ 0.64248916],\n",
       "       [ 3.22109293],\n",
       "       [-1.88426249],\n",
       "       [-3.45484912],\n",
       "       [ 1.11939032],\n",
       "       [-2.16355932],\n",
       "       [ 1.597442  ],\n",
       "       [ 1.42525789],\n",
       "       [-2.52021946],\n",
       "       [ 1.70905177],\n",
       "       [ 1.93558056],\n",
       "       [ 1.39512814],\n",
       "       [ 1.02114394],\n",
       "       [-2.29146677],\n",
       "       [ 1.19499443],\n",
       "       [ 2.01583181],\n",
       "       [-3.22983799],\n",
       "       [ 1.09034433],\n",
       "       [-2.59865498],\n",
       "       [ 0.98543713],\n",
       "       [ 0.71446492],\n",
       "       [-2.7318056 ],\n",
       "       [ 2.37138537],\n",
       "       [ 2.24732435],\n",
       "       [ 1.11929436],\n",
       "       [-1.75518705],\n",
       "       [ 1.67769187],\n",
       "       [ 2.60445982],\n",
       "       [ 0.39198205],\n",
       "       [-2.45689797],\n",
       "       [-1.40741429],\n",
       "       [ 0.72419561],\n",
       "       [-2.88984828],\n",
       "       [-0.29045385],\n",
       "       [-2.14164039],\n",
       "       [ 2.1482974 ],\n",
       "       [ 2.35552008],\n",
       "       [ 2.59978385],\n",
       "       [ 0.81409949],\n",
       "       [-3.61066579],\n",
       "       [-4.29181309],\n",
       "       [ 1.13626568],\n",
       "       [ 1.50795051],\n",
       "       [ 0.84316852],\n",
       "       [ 0.56623815],\n",
       "       [-0.11830303],\n",
       "       [ 1.23452715],\n",
       "       [ 0.84360267],\n",
       "       [-1.2275838 ],\n",
       "       [-1.47780497],\n",
       "       [ 0.65736749],\n",
       "       [ 1.90897191],\n",
       "       [ 2.16463319],\n",
       "       [ 0.66706481],\n",
       "       [-0.41858925],\n",
       "       [ 1.00005993],\n",
       "       [-1.78811433],\n",
       "       [ 2.34340156],\n",
       "       [ 0.16299369],\n",
       "       [-3.90635037],\n",
       "       [ 0.17662486],\n",
       "       [ 1.22288744],\n",
       "       [-1.06023536],\n",
       "       [ 1.39837753],\n",
       "       [-4.21862091],\n",
       "       [ 1.01352892],\n",
       "       [ 0.9077883 ],\n",
       "       [ 1.79798501],\n",
       "       [ 1.22476069],\n",
       "       [ 1.25126142],\n",
       "       [ 0.04854261],\n",
       "       [ 0.59898975],\n",
       "       [-2.7459338 ],\n",
       "       [ 0.33467903],\n",
       "       [-1.97691166],\n",
       "       [ 0.72457677],\n",
       "       [-1.60132306],\n",
       "       [ 1.05211057],\n",
       "       [-3.56649052],\n",
       "       [ 1.91830148],\n",
       "       [ 1.56740768],\n",
       "       [ 1.57487241],\n",
       "       [-2.56943879]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.transform(X_tra_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 8: Load the digits dataset (scikit-learn's toy dataset) and take the last\n",
    "1300 samples as your test set. Train a K-Nearest Neighbor (k=5, linf distance)\n",
    "model and then without using any scikit-learn method, report the \f",
    "nal values\n",
    "for Speci\f",
    "city, Sensitivity, TPR, TNR, FNR, FPR, Precision and Recall for\n",
    "Digit 3 (this digit is a positive, everything else is a negative). (15 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits= datasets.load_digits()\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split dataset into train and test\n",
    "X_tra = X[0:497]\n",
    "X_tes = X[498:]\n",
    "y_tra = y[0:497]\n",
    "y_tes = y[498:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train the model in f classes\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(5)\n",
    "clf.fit(X_tra, y_tra)\n",
    "#predict test data\n",
    "pred = clf.predict(X_tes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate TPR, Sensitivity and Recall\n",
    "TP = 0\n",
    "FN = 0\n",
    "for i in range(len(y_tes)):\n",
    "    if ((y_tes[i] == 3) & (pred[i] == 3)):\n",
    "        TP = TP + 1\n",
    "    elif ((y_tes[i] != 3) & (pred[i] != 3) & (y_tes[i] != pred[i])):\n",
    "        FN = FN + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5786802030456852"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate TPR, Sensitivity and Recall\n",
    "TPR = TP / (TP + FN)\n",
    "TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate TNR, Specificity\n",
    "TN = 0\n",
    "FP = 0\n",
    "for i in range(len(y_tes)):\n",
    "    if ((y_tes[i] == 3) & (pred[i] != 3)):\n",
    "        TN = TN + 1\n",
    "    elif ((y_tes[i] != 3) & (pred[i] == 3)):\n",
    "        FP = FP + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5517241379310345"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate TNR, Specificity\n",
    "TNR = TN / (TN + FP)\n",
    "TNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4213197969543147"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate FNR\n",
    "FNR = FN / (TP + FN)\n",
    "FNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4482758620689655"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate FPR\n",
    "FPR = FP / (FP + TN)\n",
    "FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8976377952755905"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate precisions\n",
    "Precisions = TP / (TP + FP)\n",
    "Precisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ablation experiment consists of removing one feature from an experiment,\n",
    "in order to assess the amount of additional information that feature provides\n",
    "above and beyond the others. For this section, we will use the diabetes dataset\n",
    "from scikit-learn's toy datasets. Split the data into training and testing data as\n",
    "a 90-10 split with random state of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "diabetes= datasets.load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tra, X_tes, y_tra, y_tes = train_test_split(X, y, test_size=0.1, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 9: Perform least squares regression on this dataset. Report the mean\n",
    "squared error and the mean absolute error on the test data. (5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Least squares regression\n",
    "theta,residuals,rank,s = np.linalg.lstsq(X_tra, y_tra)\n",
    "# Make predictions on the test data\n",
    "predictions = np.dot(X_tes, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin = LinearRegression()\n",
    "lin.fit(X_tra, y_tra)\n",
    "predictions = lin.predict(X_tes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2155.96465103\n"
     ]
    }
   ],
   "source": [
    "# Mean squared error calculation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print (mean_squared_error(y_tes, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.3181336987\n"
     ]
    }
   ],
   "source": [
    "# Mean absolute error calculation\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print (mean_absolute_error(y_tes, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 10: Repeat the experiment from Question 10 for all possible values\n",
    "of ablation (i.e., removing the feature 1 only, then removing the feature 2 only,\n",
    "and so on). Report all MSEs. (10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_tra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.delete(X_tra, np.s_[1],1)\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 2152.80664218 when remove the 0 feature\n",
      "MSE = 2259.13307937 when remove the 1 feature\n",
      "MSE = 2783.51448185 when remove the 2 feature\n",
      "MSE = 2424.772348 when remove the 3 feature\n",
      "MSE = 2187.59951938 when remove the 4 feature\n",
      "MSE = 2167.51760615 when remove the 5 feature\n",
      "MSE = 2159.15148251 when remove the 6 feature\n",
      "MSE = 2153.06317113 when remove the 7 feature\n",
      "MSE = 2335.17338461 when remove the 8 feature\n",
      "MSE = 2165.86619219 when remove the 9 feature\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    X_tra_rem = np.delete(X_tra, np.s_[i],1)\n",
    "    X_tes_rem = np.delete(X_tes, np.s_[i],1)\n",
    "    lin = LinearRegression()\n",
    "    lin.fit(X_tra_rem, y_tra)\n",
    "    predictions = lin.predict(X_tes_rem)\n",
    "    a = mean_squared_error(y_tes, predictions)\n",
    "    print ('MSE = ' + str(a) + ' when remove the %i feature' %i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 11: Based on the MSE values obtained from Question 11, which fea-\n",
    "tures do you deem the most/least signi\f",
    "cant and why? (5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results of questions 10, we can draw the conclusion that the second is the most significant and the 7th feature is the least significant feature. Actully, we can tell the importance of each feature from the ESMs change before and after removing these features.\n",
    "When we remove the 2nd feature, the magnititude change of MSE is the largest, and when we remove the 7th feature, the magnititude change of MSE is least. Therefore, the second feature is most significant feature as to this linear regression and the 7th feature is the least significant feature to this linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
