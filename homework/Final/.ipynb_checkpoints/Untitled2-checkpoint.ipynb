{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "   g = gzip.open(path, 'rb')\n",
    "   for l in g:\n",
    "     yield eval(l)\n",
    "    \n",
    "#getDF but spererate helpful field into outOf and nHelpful two fields\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        a = d['helpful']\n",
    "        d.update(a) #spererate helpful field into outOf and nHelpful two fields\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read raw data into dataframe without outOf = 0\n",
    "path_train = '/Users/xiasong/Documents/Class_2016/DSE/DSE220/homework/Final/train.json.gz'\n",
    "path_test = '/Users/xiasong/Documents/Class_2016/DSE/DSE220/homework/Final/test_Helpful.json.gz'\n",
    "df_raw = getDF(path_train)\n",
    "test_df_raw = getDF(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in our analysis, the three columns (cateoryID, categories, price,helpful) are not useful\n",
    "df = df_raw.drop(['categoryID', 'categories', 'price', 'helpful'], axis=1)\n",
    "test_df = test_df_raw.drop(['categoryID', 'categories', 'price', 'helpful'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract each review text length\n",
    "reviewlen = []\n",
    "for i in df['reviewText']:\n",
    "    a = i.split()\n",
    "    reviewlen.append(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract each review summary length\n",
    "summarylen = []\n",
    "for i in df['summary']:\n",
    "    a = i.split()\n",
    "    summarylen.append(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract each review summary length\n",
    "import string\n",
    "summarycappun = []\n",
    "for i in df['summary']:\n",
    "    a = sum(1 for c in i if (c.isupper() or c in string.punctuation))\n",
    "    summarycappun.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate helpratio, positive number of helpful vote to total number of vote\n",
    "a = len(df['outOf'])\n",
    "b = df['outOf']\n",
    "c = df['nHelpful']\n",
    "helpratio = []\n",
    "for i in range(a):\n",
    "    if b[i] == 0 & c[i] == 0:\n",
    "        helpratio.append(0.5)\n",
    "    else:\n",
    "        d = c[i]/b[i]\n",
    "        helpratio.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['reviewlen'] = reviewlen \n",
    "df['summarylen'] = summarylen\n",
    "df['summarycappun'] = summarycappun \n",
    "df['helpratio'] =helpratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate summaryratio, length of summary to length of review text\n",
    "a = len(df['outOf'])\n",
    "b = df['summarylen']\n",
    "c = df['reviewlen']\n",
    "summaryratio = []\n",
    "for i in range(a):\n",
    "    if (b[i] == 0):\n",
    "        summaryratio.append(0)\n",
    "    elif (c[i] == 0):\n",
    "        summaryratio.append(0)\n",
    "    else:\n",
    "        d = b[i]/c[i]\n",
    "        summaryratio.append(d)\n",
    "df['summaryratio'] = summaryratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate summarycapratio, number of cap letter and punctuations to length of summary\n",
    "a = len(df['outOf'])\n",
    "b = df['summarycappun']\n",
    "c = df['summarylen']\n",
    "summarycapratio = []\n",
    "for i in range(a):\n",
    "    if (b[i] == 0):\n",
    "        summarycapratio.append(0)\n",
    "    elif (c[i] == 0):\n",
    "        summarycapratio.append(0)\n",
    "    else:\n",
    "        d = b[i]/c[i]\n",
    "        summarycapratio.append(d)\n",
    "df['summarycapratio'] = summarycapratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract each review summary length\n",
    "import string\n",
    "reviewcap = []\n",
    "for i in df['reviewText']:\n",
    "    a = sum(1 for c in i if c.isupper())\n",
    "    reviewcap.append(a)\n",
    "df['reviewcap'] = reviewcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#according to helpratio classify the review as two group (helpratio > 0.6), 1: helpful (1), 2: not helpful (0)\n",
    "a = len(df['outOf'])\n",
    "b = df['helpratio']\n",
    "c = []\n",
    "for i in range(a):\n",
    "    if b[i] > 0.2:\n",
    "        c.append(1)\n",
    "    else:\n",
    "        c.append(0)\n",
    "df['helpgroup'] = c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## According review text content to classify review as helpful group and unhelpful group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " \"I ordered according to the size chart but it's uncomfortably small, so buy a size larger and you'll be fine. Other than that this leotard is great.\",\n",
       " 'These are cute, but they are a little small.  When I put them on, my legs stretch the fabric making the black fade out.')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#according to review text\n",
    "train_data = list(df['reviewText'])\n",
    "y_data = list(df['helpgroup'])\n",
    "test_data = list(test_df['reviewText'])\n",
    "y_data[0], test_data[0], train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = \\\n",
    "        train_test_split(train_data, y_data, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train data processing\n",
    "from nltk.corpus import stopwords\n",
    "X_train = []\n",
    "exclude = set(string.punctuation)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "for i in range(len(x_train)):\n",
    "    A = x_train[i].lower() #lowercase for each word\n",
    "    A = ''.join(ch for ch in A if ch not in exclude) #remove punctuation\n",
    "    filtered_words = [word for word in A.split() if word not in stop_words] #remove stopwords\n",
    "    B = ' '.join(word for word in filtered_words)\n",
    "    X_train.append(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#val data processing\n",
    "from nltk.corpus import stopwords\n",
    "X_val = []\n",
    "exclude = set(string.punctuation)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "for i in range(len(x_val)):\n",
    "    A = x_val[i].lower() #lowercase for each word\n",
    "    A = ''.join(ch for ch in A if ch not in exclude) #remove punctuation\n",
    "    filtered_words = [word for word in A.split() if word not in stop_words] #remove stopwords\n",
    "    B = ' '.join(word for word in filtered_words)\n",
    "    X_val.append(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test data processing\n",
    "X_test = []\n",
    "exclude = set(string.punctuation)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "for i in range(len(test_data)):\n",
    "    C = test_data[i].lower() #lowercase for each word\n",
    "    C = ''.join(ch for ch in C if ch not in exclude) #remove punctuation\n",
    "    filtered_words = [word for word in C.split() if word not in stop_words] #remove stopwords\n",
    "    D = ' '.join(word for word in filtered_words)\n",
    "    X_test.append(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160000, 1000) (40000, 1000) (14000, 1000)\n"
     ]
    }
   ],
   "source": [
    "# TfidfVectorizer for train data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "count_vect = TfidfVectorizer(max_features = 1000)\n",
    "X_train_counts = count_vect.fit_transform(X_train) #fit and transform\n",
    "X_val_counts = count_vect.transform(X_val)\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "print (X_train_counts.shape, X_val_counts.shape, X_test_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9385\n"
     ]
    }
   ],
   "source": [
    "# Perceptron Model\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = Perceptron()\n",
    "# fit\n",
    "clf.fit(X_train_counts, y_train)\n",
    "# predict\n",
    "#prediction_test = clf.predict(X_test_counts)\n",
    "prediction_per = clf.predict(X_val_counts)\n",
    "#evaluate\n",
    "print (accuracy_score(y_val, prediction_per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.960425\n"
     ]
    }
   ],
   "source": [
    "#MultinomialNB Model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(X_train_counts, y_train)\n",
    "#prediction_test = clf.predict(X_test_counts)\n",
    "prediction_nb = clf.predict(X_val_counts)\n",
    "print (accuracy_score(y_val, prediction_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9603\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=5)\n",
    "clf.fit(X_train_counts, y_train)\n",
    "#prediction_test = clf.predict(X_test_counts)\n",
    "prediction_dec = clf.predict(X_val_counts)\n",
    "print (accuracy_score(y_val, prediction_dec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.960425\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "clf = RandomForestClassifier(max_depth=5)\n",
    "clf.fit(X_train_counts, y_train)\n",
    "#prediction_test = clf.predict(X_test_counts)\n",
    "prediction_ran = clf.predict(X_val_counts)\n",
    "print (accuracy_score(y_val, prediction_ran))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9604\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X_train_counts, y_train)\n",
    "#prediction_test = clf.predict(X_test_counts)\n",
    "prediction_ada = clf.predict(X_val_counts)\n",
    "print (accuracy_score(y_val, prediction_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model to predict test data helpfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "nnratio_filter = np.where((df['helpratio'] >= 0.6) & (df['helpratio'] <= 0.99))\n",
    "nnratio_filter = list(nnratio_filter[0])\n",
    "nnratio_df = df.loc[nnratio_filter,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.179975\n"
     ]
    }
   ],
   "source": [
    "# we will use the nnratio_df to simulate our predictive model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "X = nnratio_df[['outOf']].as_matrix(columns=None)\n",
    "X_val = df_val[['outOf']].as_matrix(columns=None)\n",
    "y = nnratio_df['nHelpful']\n",
    "y_val = df_val['nHelpful']\n",
    "theta,residuals,rank,s = np.linalg.lstsq(X, y)\n",
    "predictions_val = np.dot(X_val, theta)\n",
    "prediciotns_val = list(predictions_val)\n",
    "predictions = []\n",
    "for i in predictions_val:\n",
    "    predictions.append(round(i))\n",
    "predictions = np.asarray(predictions)\n",
    "print (mean_absolute_error(y_val, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=5)\n",
    "clf.fit(X_train_counts, y_train)\n",
    "prediction_val = clf.predict(X_val_counts)\n",
    "prediction_test = clf.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=list(prediction_val)\n",
    "b = len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "X = nnratio_df[['outOf']].as_matrix(columns=None)\n",
    "X_val = list(df_val['outOf'])\n",
    "y = nnratio_df['nHelpful']\n",
    "y_val = df_val['nHelpful']\n",
    "theta,residuals,rank,s = np.linalg.lstsq(X, y)\n",
    "pred_val = []\n",
    "for i in range(b):\n",
    "    if a[i] == 0:\n",
    "        pred_val.append(X_val[i])\n",
    "    else:\n",
    "        c = np.dot(X_val[i], theta)\n",
    "        c = c[0]\n",
    "        pred_val.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.187689805381\n"
     ]
    }
   ],
   "source": [
    "predictions = np.asarray(pred_val)\n",
    "print (mean_absolute_error(y_val, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## According to mutiple features to classify helpful or not helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewHash</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>outOf</th>\n",
       "      <th>nHelpful</th>\n",
       "      <th>reviewlen</th>\n",
       "      <th>summarylen</th>\n",
       "      <th>summarycappun</th>\n",
       "      <th>helpratio</th>\n",
       "      <th>summaryratio</th>\n",
       "      <th>summarycapratio</th>\n",
       "      <th>reviewcap</th>\n",
       "      <th>helpgroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I655355328</td>\n",
       "      <td>U745881038</td>\n",
       "      <td>3.0</td>\n",
       "      <td>These are cute, but they are a little small.  ...</td>\n",
       "      <td>R115160670</td>\n",
       "      <td>05 20, 2014</td>\n",
       "      <td>Cute</td>\n",
       "      <td>1400544000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I241092314</td>\n",
       "      <td>U023577405</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I love the look of this bra, it is what I want...</td>\n",
       "      <td>R800651687</td>\n",
       "      <td>02 7, 2013</td>\n",
       "      <td>Beautiful but size runs small</td>\n",
       "      <td>1360195200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       itemID  reviewerID  rating  \\\n",
       "0  I655355328  U745881038     3.0   \n",
       "1  I241092314  U023577405     4.0   \n",
       "\n",
       "                                          reviewText  reviewHash   reviewTime  \\\n",
       "0  These are cute, but they are a little small.  ...  R115160670  05 20, 2014   \n",
       "1  I love the look of this bra, it is what I want...  R800651687   02 7, 2013   \n",
       "\n",
       "                         summary  unixReviewTime  outOf  nHelpful  reviewlen  \\\n",
       "0                           Cute      1400544000      0         0         24   \n",
       "1  Beautiful but size runs small      1360195200      0         0         57   \n",
       "\n",
       "   summarylen  summarycappun  helpratio  summaryratio  summarycapratio  \\\n",
       "0           1              1        0.5      0.041667              1.0   \n",
       "1           5              1        0.5      0.087719              0.2   \n",
       "\n",
       "   reviewcap  helpgroup  \n",
       "0          3          1  \n",
       "1          8          1  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>outOf</th>\n",
       "      <th>reviewlen</th>\n",
       "      <th>summarylen</th>\n",
       "      <th>summarycappun</th>\n",
       "      <th>summaryratio</th>\n",
       "      <th>summarycapratio</th>\n",
       "      <th>reviewcap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  outOf  reviewlen  summarylen  summarycappun  summaryratio  \\\n",
       "0     3.0      0         24           1              1      0.041667   \n",
       "1     4.0      0         57           5              1      0.087719   \n",
       "2     3.0      2         28           3              4      0.107143   \n",
       "3     4.0      0         31           2              2      0.064516   \n",
       "4     5.0      1         77           2              1      0.025974   \n",
       "\n",
       "   summarycapratio  reviewcap  \n",
       "0         1.000000          3  \n",
       "1         0.200000          8  \n",
       "2         1.333333          2  \n",
       "3         1.000000          2  \n",
       "4         0.500000          8  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df = df.drop(['itemID', 'reviewerID', 'reviewText', 'reviewHash', 'reviewTime','unixReviewTime','summary','nHelpful','helpratio','helpgroup'], axis=1)\n",
    "y_df = df['helpgroup']\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in y_df:\n",
    "    if i >1:\n",
    "        print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#split train data into train and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "        train_test_split(X_df, y_df, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in y_val:\n",
    "    if i >1:\n",
    "        print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9596\n"
     ]
    }
   ],
   "source": [
    "# Perceptron Model\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = Perceptron()\n",
    "clf.fit(X_train, y_train)\n",
    "#prediction_test = clf.predict(X_test_counts)\n",
    "prediction_per = clf.predict(X_val)\n",
    "#evaluate\n",
    "print (accuracy_score(y_val, prediction_per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.941425\n"
     ]
    }
   ],
   "source": [
    "#MultinomialNB Model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(X_train, y_train)\n",
    "#prediction_test = clf.predict(X_test_counts)\n",
    "prediction_nb = clf.predict(X_val)\n",
    "print (accuracy_score(y_val, prediction_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9382\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "#prediction_test = clf.predict(X_test_counts)\n",
    "prediction_gnb = clf.predict(X_val)\n",
    "print (accuracy_score(y_val, prediction_gnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.960425\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "clf = RandomForestClassifier(max_depth=5)\n",
    "clf.fit(X_train, y_train)\n",
    "#prediction_test = clf.predict(X_test_counts)\n",
    "prediction_ran = clf.predict(X_val)\n",
    "print (accuracy_score(y_val, prediction_ran))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.959175\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "#prediction_test = clf.predict(X_test_counts)\n",
    "prediction_ada = clf.predict(X_val)\n",
    "print (accuracy_score(y_val, prediction_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.960425\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(alpha=1)\n",
    "clf.fit(X_train, y_train)\n",
    "#prediction_test = clf.predict(X_test_counts)\n",
    "prediction_ran = clf.predict(X_val)\n",
    "print (accuracy_score(y_val, prediction_ran))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95345\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(3)\n",
    "clf.fit(X_train, y_train)\n",
    "#prediction_test = clf.predict(X_test_counts)\n",
    "prediction_ran = clf.predict(X_val)\n",
    "print (accuracy_score(y_val, prediction_ran))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## According to simulation accuracy, we select AdaBoost classify our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate features for test dataframe\n",
    "#extract each review text length\n",
    "reviewlen = []\n",
    "for i in test_df['reviewText']:\n",
    "    a = i.split()\n",
    "    reviewlen.append(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract each review summary length\n",
    "summarylen = []\n",
    "for i in test_df['summary']:\n",
    "    a = i.split()\n",
    "    summarylen.append(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract each review summary length\n",
    "import string\n",
    "summarycappun = []\n",
    "for i in test_df['summary']:\n",
    "    a = sum(1 for c in i if (c.isupper() or c in string.punctuation))\n",
    "    summarycappun.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['reviewlen'] = reviewlen \n",
    "test_df['summarylen'] = summarylen\n",
    "test_df['summarycappun'] = summarycappun "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate summaryratio, length of summary to length of review text\n",
    "a = len(test_df['outOf'])\n",
    "b = test_df['summarylen']\n",
    "c = test_df['reviewlen']\n",
    "summaryratio = []\n",
    "for i in range(a):\n",
    "    if (b[i] == 0):\n",
    "        summaryratio.append(0)\n",
    "    elif (c[i] == 0):\n",
    "        summaryratio.append(0)\n",
    "    else:\n",
    "        d = b[i]/c[i]\n",
    "        summaryratio.append(d)\n",
    "test_df['summaryratio'] = summaryratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate summarycapratio, number of cap letter and punctuations to length of summary\n",
    "a = len(test_df['outOf'])\n",
    "b = test_df['summarycappun']\n",
    "c = test_df['summarylen']\n",
    "summarycapratio = []\n",
    "for i in range(a):\n",
    "    if (b[i] == 0):\n",
    "        summarycapratio.append(0)\n",
    "    elif (c[i] == 0):\n",
    "        summarycapratio.append(0)\n",
    "    else:\n",
    "        d = b[i]/c[i]\n",
    "        summarycapratio.append(d)\n",
    "test_df['summarycapratio'] = summarycapratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract each review summary length\n",
    "import string\n",
    "reviewcap = []\n",
    "for i in test_df['reviewText']:\n",
    "    a = sum(1 for c in i if c.isupper())\n",
    "    reviewcap.append(a)\n",
    "test_df['reviewcap'] = reviewcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop(['itemID', 'reviewerID', 'reviewText', 'reviewHash', 'reviewTime','unixReviewTime','summary'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>outOf</th>\n",
       "      <th>reviewlen</th>\n",
       "      <th>summarylen</th>\n",
       "      <th>summarycappun</th>\n",
       "      <th>summaryratio</th>\n",
       "      <th>summarycapratio</th>\n",
       "      <th>reviewcap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  outOf  reviewlen  summarylen  summarycappun  summaryratio  \\\n",
       "0     3.0      2         27           2              1      0.074074   \n",
       "1     4.0      0         27           2              1      0.074074   \n",
       "2     5.0      1         23           4              2      0.173913   \n",
       "3     5.0      1        135           4              4      0.029630   \n",
       "4     4.0      0         38           3              4      0.078947   \n",
       "\n",
       "   summarycapratio  reviewcap  \n",
       "0         0.500000          2  \n",
       "1         0.500000          2  \n",
       "2         0.500000          3  \n",
       "3         1.000000         11  \n",
       "4         1.333333          6  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## According to simulation accuracy, we select decision tree classify our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.960425\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "clf = RandomForestClassifier(max_depth=5)\n",
    "clf.fit(X_train, y_train)\n",
    "prediction_test = clf.predict(X_test)\n",
    "prediction_ran = clf.predict(X_val)\n",
    "print (accuracy_score(y_val, prediction_ran))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df = test_df.drop(['helpgroup', 'predictions'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df['helpgroup'] = list(prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewHash</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>outOf</th>\n",
       "      <th>reviewlen</th>\n",
       "      <th>summarylen</th>\n",
       "      <th>summarycappun</th>\n",
       "      <th>summaryratio</th>\n",
       "      <th>summarycapratio</th>\n",
       "      <th>reviewcap</th>\n",
       "      <th>helpgroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I520932398</td>\n",
       "      <td>U816789534</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I ordered according to the size chart but it's...</td>\n",
       "      <td>R157684793</td>\n",
       "      <td>07 15, 2011</td>\n",
       "      <td>Too small</td>\n",
       "      <td>1310688000</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I969532331</td>\n",
       "      <td>U987148846</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Super thin but really cute and not cheap-looki...</td>\n",
       "      <td>R732719858</td>\n",
       "      <td>07 17, 2013</td>\n",
       "      <td>Fun hoodie</td>\n",
       "      <td>1374019200</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I149943341</td>\n",
       "      <td>U628436634</td>\n",
       "      <td>5.0</td>\n",
       "      <td>It was a present for my sis, and she loves Fle...</td>\n",
       "      <td>R352659313</td>\n",
       "      <td>12 8, 2013</td>\n",
       "      <td>A Perfect hook up</td>\n",
       "      <td>1386460800</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I909025835</td>\n",
       "      <td>U924107228</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I love this thing!  I guess they don't make th...</td>\n",
       "      <td>R277416618</td>\n",
       "      <td>11 22, 2012</td>\n",
       "      <td>I love this thing...</td>\n",
       "      <td>1353542400</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I228439768</td>\n",
       "      <td>U060135484</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I liked it and I wear it...it's a little bit s...</td>\n",
       "      <td>R645892076</td>\n",
       "      <td>04 1, 2014</td>\n",
       "      <td>I liked it...</td>\n",
       "      <td>1396310400</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       itemID  reviewerID  rating  \\\n",
       "0  I520932398  U816789534     3.0   \n",
       "1  I969532331  U987148846     4.0   \n",
       "2  I149943341  U628436634     5.0   \n",
       "3  I909025835  U924107228     5.0   \n",
       "4  I228439768  U060135484     4.0   \n",
       "\n",
       "                                          reviewText  reviewHash   reviewTime  \\\n",
       "0  I ordered according to the size chart but it's...  R157684793  07 15, 2011   \n",
       "1  Super thin but really cute and not cheap-looki...  R732719858  07 17, 2013   \n",
       "2  It was a present for my sis, and she loves Fle...  R352659313   12 8, 2013   \n",
       "3  I love this thing!  I guess they don't make th...  R277416618  11 22, 2012   \n",
       "4  I liked it and I wear it...it's a little bit s...  R645892076   04 1, 2014   \n",
       "\n",
       "                summary  unixReviewTime  outOf  reviewlen  summarylen  \\\n",
       "0             Too small      1310688000      2         27           2   \n",
       "1            Fun hoodie      1374019200      0         27           2   \n",
       "2     A Perfect hook up      1386460800      1         23           4   \n",
       "3  I love this thing...      1353542400      1        135           4   \n",
       "4         I liked it...      1396310400      0         38           3   \n",
       "\n",
       "   summarycappun  summaryratio  summarycapratio  reviewcap  helpgroup  \n",
       "0              1      0.074074         0.500000          2          1  \n",
       "1              1      0.074074         0.500000          2          1  \n",
       "2              2      0.173913         0.500000          3          1  \n",
       "3              4      0.029630         1.000000         11          1  \n",
       "4              4      0.078947         1.333333          6          1  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "nnratio_filter = np.where((df['helpratio'] >= 0.6) & (df['helpratio'] <= 0.99))\n",
    "nnratio_filter = list(nnratio_filter[0])\n",
    "nnratio_df = df.loc[nnratio_filter,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10401, 18)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnratio_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = nnratio_df[['outOf']].as_matrix(columns=None)\n",
    "y = nnratio_df['nHelpful']\n",
    "theta,residuals,rank,s = np.linalg.lstsq(X, y)\n",
    "X_test = test_df[['outOf']].as_matrix(columns=None)\n",
    "predictions_test = np.dot(X_test, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = list(predictions_test)\n",
    "predictions = []\n",
    "for i in predictions_test:\n",
    "    predictions.append(round(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(prediction_test)\n",
    "c = list(test_df['outOf'])\n",
    "pred_test = []\n",
    "for i in range(len(a)):\n",
    "    if a[i] == 0:\n",
    "        pred_test.append(c[i])\n",
    "    else:\n",
    "        b = predictions[i]\n",
    "        pred_test.append(b)\n",
    "test_df['predictions'] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Helpful.txt\", 'w')\n",
    "a = test_df['reviewerID']\n",
    "b = test_df['itemID']\n",
    "c = test_df['outOf']\n",
    "d = test_df['predictions']\n",
    "for i in range(len(a)):\n",
    "    e = a[i]\n",
    "    f = b[i]\n",
    "    g = c[i]\n",
    "    h = d[i]\n",
    "    predictions.write(e + '-' + f + '-' + str(g) + ',' + str(h) + '\\n')\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
