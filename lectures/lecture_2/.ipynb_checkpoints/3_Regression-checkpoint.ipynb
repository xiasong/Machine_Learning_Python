{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Outline:\n",
    "    Load Boston housing prices dataset\n",
    "    Split data into test and training\n",
    "    Least Squares Regression to predict housing prices\n",
    "    Mean Squared Error\n",
    "    Mean Absolute Error\n",
    "    R2 score\n",
    "    Regularization\n",
    "    Effect of random features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.32000000e-03   1.80000000e+01   2.31000000e+00   0.00000000e+00\n",
      "   5.38000000e-01   6.57500000e+00   6.52000000e+01   4.09000000e+00\n",
      "   1.00000000e+00   2.96000000e+02   1.53000000e+01   3.96900000e+02\n",
      "   4.98000000e+00]\n",
      "(506, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "print (X[0])\n",
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 24. ,  21.6,  34.7,  33.4,  36.2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.32000000e-03,   1.80000000e+01,   2.31000000e+00,\n",
       "          0.00000000e+00,   5.38000000e-01,   6.57500000e+00,\n",
       "          6.52000000e+01,   4.09000000e+00,   1.00000000e+00,\n",
       "          2.96000000e+02,   1.53000000e+01,   3.96900000e+02,\n",
       "          4.98000000e+00],\n",
       "       [  2.73100000e-02,   0.00000000e+00,   7.07000000e+00,\n",
       "          0.00000000e+00,   4.69000000e-01,   6.42100000e+00,\n",
       "          7.89000000e+01,   4.96710000e+00,   2.00000000e+00,\n",
       "          2.42000000e+02,   1.78000000e+01,   3.96900000e+02,\n",
       "          9.14000000e+00],\n",
       "       [  2.72900000e-02,   0.00000000e+00,   7.07000000e+00,\n",
       "          0.00000000e+00,   4.69000000e-01,   7.18500000e+00,\n",
       "          6.11000000e+01,   4.96710000e+00,   2.00000000e+00,\n",
       "          2.42000000e+02,   1.78000000e+01,   3.92830000e+02,\n",
       "          4.03000000e+00],\n",
       "       [  3.23700000e-02,   0.00000000e+00,   2.18000000e+00,\n",
       "          0.00000000e+00,   4.58000000e-01,   6.99800000e+00,\n",
       "          4.58000000e+01,   6.06220000e+00,   3.00000000e+00,\n",
       "          2.22000000e+02,   1.87000000e+01,   3.94630000e+02,\n",
       "          2.94000000e+00],\n",
       "       [  6.90500000e-02,   0.00000000e+00,   2.18000000e+00,\n",
       "          0.00000000e+00,   4.58000000e-01,   7.14700000e+00,\n",
       "          5.42000000e+01,   6.06220000e+00,   3.00000000e+00,\n",
       "          2.22000000e+02,   1.87000000e+01,   3.96900000e+02,\n",
       "          5.33000000e+00]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Split data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "\n",
    "# Least squares regression\n",
    "theta,residuals,rank,s = np.linalg.lstsq(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = np.dot(X_test, theta)\n",
    "# Let's see the output on training data as well, to see the training error\n",
    "y_true_pred = np.dot(X_train, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE calculation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print (mean_squared_error(y_test, predictions))\n",
    "print (mean_squared_error(y_train, y_true_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE calculation\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print (mean_absolute_error(y_test, predictions))\n",
    "print (mean_absolute_error(y_train, y_true_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 Score calculation\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print (r2_score(y_train, y_true_pred))\n",
    "print (r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Add one's column!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.c_[X, np.ones(len(X))]\n",
    "\n",
    "# Split data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "\n",
    "# Least squares regression\n",
    "theta,residuals,rank,s = np.linalg.lstsq(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = np.dot(X_test, theta)\n",
    "# Let's see the output on training data as well, to see the training error\n",
    "y_true_pred = np.dot(X_train, theta)\n",
    "\n",
    "# MSE calculation\n",
    "print (mean_squared_error(y_test, predictions))\n",
    "print (mean_squared_error(y_train, y_true_pred))\n",
    "\n",
    "# MAE calculation\n",
    "print (mean_absolute_error(y_test, predictions))\n",
    "print (mean_absolute_error(y_train, y_true_pred))\n",
    "\n",
    "# R2 Score calculation\n",
    "print (r2_score(y_train, y_true_pred))\n",
    "print (r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Regularization and Using Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "### Gradient descent ###\n",
    "\n",
    "# Objective\n",
    "def f(theta, X, y, lam):\n",
    "    theta = np.matrix(theta).T\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y).T\n",
    "    diff = X*theta - y\n",
    "    diffSq = diff.T*diff\n",
    "    diffSqReg = diffSq / len(X) + lam*(theta.T*theta)\n",
    "    #print (\"offset =\", diffSqReg.flatten().tolist())\n",
    "    return diffSqReg.flatten().tolist()[0]\n",
    "\n",
    "# Derivative\n",
    "def fprime(theta, X, y, lam):\n",
    "    theta = np.matrix(theta).T\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y).T\n",
    "    diff = X*theta - y\n",
    "    res = 2*X.T*diff / len(X) + 2*lam*theta\n",
    "    #print (\"gradient =\", np.array(res.flatten().tolist()[0]))\n",
    "    return np.array(res.flatten().tolist()[0])\n",
    "\n",
    "theta, _, _ = scipy.optimize.fmin_l_bfgs_b(f, [0]*14, fprime, args = (X_train, y_train, 0.1))\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = np.dot(X_test, theta)\n",
    "# Let's see the output on training data as well, to see the training error\n",
    "y_true_pred = np.dot(X_train, theta)\n",
    "\n",
    "# MSE calculation\n",
    "print (mean_squared_error(y_test, predictions))\n",
    "print (mean_squared_error(y_train, y_true_pred))\n",
    "\n",
    "# MAE calculation\n",
    "print (mean_absolute_error(y_test, predictions))\n",
    "print (mean_absolute_error(y_train, y_true_pred))\n",
    "\n",
    "# R2 Score calculation\n",
    "print (r2_score(y_train, y_true_pred))\n",
    "print (r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Random features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import random\n",
    "\n",
    "def feature():\n",
    "    return [random.random() for x in range(13)]\n",
    "\n",
    "X_train2 = [feature() for d in X_train]\n",
    "X_test2 = [feature() for d in X_test]\n",
    "\n",
    "theta,residuals,rank,s = numpy.linalg.lstsq(X_train2, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = np.dot(X_test2, theta)\n",
    "# Let's see the output on training data as well, to see the training error\n",
    "y_true_pred = np.dot(X_train2, theta)\n",
    "\n",
    "# MSE calculation\n",
    "print (mean_squared_error(y_test, predictions))\n",
    "print (mean_squared_error(y_train, y_true_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Lasso Model Selection - AIC, BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC\n",
    "from sklearn import datasets\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "X = np.c_[X, rng.randn(X.shape[0], 14)]  # add some bad features\n",
    "\n",
    "# normalize data as done by Lars to allow for comparison\n",
    "X /= np.sqrt(np.sum(X ** 2, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LassoLarsIC: least angle regression with BIC/AIC criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bic = LassoLarsIC(criterion='bic')\n",
    "t1 = time.time()\n",
    "model_bic.fit(X, y)\n",
    "t_bic = time.time() - t1\n",
    "alpha_bic_ = model_bic.alpha_\n",
    "\n",
    "model_aic = LassoLarsIC(criterion='aic')\n",
    "model_aic.fit(X, y)\n",
    "alpha_aic_ = model_aic.alpha_\n",
    "\n",
    "def plot_ic_criterion(model, name, color):\n",
    "    alpha_ = model.alpha_\n",
    "    alphas_ = model.alphas_\n",
    "    criterion_ = model.criterion_\n",
    "    plt.plot(-np.log10(alphas_), criterion_, '--', color=color,\n",
    "             linewidth=3, label='%s criterion' % name)\n",
    "    plt.xlabel('-log(alpha)')\n",
    "    plt.ylabel('criterion')\n",
    "\n",
    "plt.figure()\n",
    "plot_ic_criterion(model_aic, 'AIC', 'b')\n",
    "plot_ic_criterion(model_bic, 'BIC', 'r')\n",
    "plt.legend()\n",
    "plt.title('Information-criterion for model selection (training time %.3fs)'\n",
    "          % t_bic)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
