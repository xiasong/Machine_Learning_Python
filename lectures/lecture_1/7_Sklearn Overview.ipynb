{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This notebook gives an overview of Python's scikit-learn library.\n",
    "Outline:\n",
    "    Datasets\n",
    "    Splitting data into test/train/validation sets\n",
    "    Learning and predicting\n",
    "    Parameter tuning\n",
    "    Model persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Loading a sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Provides toy datasets\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# load the digits dataset\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About the dataset - \n",
    "Iris is a flower. The flower can belong to one of three categories - Setosa, Versicolour, and Virginica. Think of it as\n",
    "being equivalent to red rose, white rose and pink rose. \n",
    "\n",
    "Given the flower's features such as length and width of petals, we need to classify the flower into its correct category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imread, imresize\n",
    "\n",
    "img = imread('./iris.jpg')\n",
    "\n",
    "# Show the original image\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd_df = pd.DataFrame(iris.data)\n",
    "pd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# View the dimensions\n",
    "pd_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Splitting data into validation, testing and training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = iris.data[:, :2]\n",
    "y = iris.target\n",
    "\n",
    "# 20% of data as testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "\n",
    "# 20% of TRAINING data as validation set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Train a SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import the classifier\n",
    "from sklearn import svm\n",
    "\n",
    "# C is a hyper-parameter\n",
    "clf = svm.SVC(C=10)\n",
    "\n",
    "# Training a classifier\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Predict on the validation set to see accuracy\n",
    "import numpy as np\n",
    "\n",
    "predictions = clf.predict(X_valid)\n",
    "print ('Accuracy = ' + str(np.sum(predictions == y_valid)/len(y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "print ('Accuracy = ' + str(np.sum(predictions == y_test)/len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# How to select the best value of C?\n",
    "# See the value of C that gives best accuracy on validation data\n",
    "\n",
    "initial_C = 0.1\n",
    "\n",
    "C = initial_C\n",
    "best_acc = 0.0\n",
    "best_C = initial_C\n",
    "step_size = 5 # can be toned down for a better prediction\n",
    "\n",
    "while C < 100:\n",
    "    clf = svm.SVC(C=C)\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy = np.sum(clf.predict(X_valid)==y_valid)/len(y_valid)\n",
    "    print ('Accuracy at C = ' + str(C) + ' is ' + str(accuracy))\n",
    "    if (accuracy > best_acc):\n",
    "        best_acc = accuracy\n",
    "        best_C = C\n",
    "    C += step_size\n",
    "print (\"\")\n",
    "print ('Best C = ' + str(best_C) + '. It has an accuracy of ' + str(best_acc))\n",
    "\n",
    "clf = svm.SVC(C=best_C)\n",
    "clf.fit(X_train, y_train) # you can use X_train + X_valid here too if you feel more data will be helpful\n",
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize\n",
    "grd = GradientBoostingClassifier(n_estimators=50)\n",
    "# Train\n",
    "grd.fit(X_train, y_train)\n",
    "# Predict\n",
    "preds = grd.predict(X_valid)\n",
    "# Report\n",
    "accuracy = np.sum(preds == y_valid)/len(y_valid)\n",
    "print ('Validation accuracy = ' + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Model persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# It is possible to save a model in the scikit by using Python’s built-in persistence model, namely pickle \n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "clf = svm.SVC()\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "clf.fit(X, y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "s = pickle.dumps(clf)\n",
    "clf2 = pickle.loads(s)\n",
    "pred = clf2.predict(X[0:1])\n",
    "print (pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In the specific case of the scikit, it may be more interesting to use joblib’s replacement of pickle (joblib.dump & joblib.load), which is more efficient on big data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(clf, 'filename.pkl')  #.pkl means a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = joblib.load('filename.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Other type of models such as regressors, clustering mechansims etc. will be discussed later. This module was only to give a brief overview of the capabilities of sklearn"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
